/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Meta-ONT Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs

params {
    
    // Input and output options
    input                      = "assets/samplesheet"
    outdir                     = 'results/test'

    //please enter 'illumina', 'pacbio', or 'nanopore'
    read_type                  = 'nanopore'

    //replace value with [true] to assemble reads with meta spades or meta flye
    metagenomic_sample                = true

    // Designate which processes the workflow will execute
    skip_subsample                    = true
    skip_porechop                     = true   //should always be skipped unless reads have not been trimmed by dorado
    skip_metamaps                     = true
    skip_nonpareil                    = true
    skip_alignment_based_filtering    = true  //filters reads based on primary reference alignment
    skip_fastq_screen                 = true
    skip_kraken2                      = true
    skip_kraken2_parse_reads_by_taxon = true  //works the same as KrakenTools' extract_kraken_reads.py
    skip_kraken2_protein              = true  //uses kraken2 to perform a blastx-like translated search
    skip_filter_by_kraken2_protein    = true  //only keep reads that translate to a specific protein
    skip_assembly                     = true
    skip_medaka                       = true
    skip_binning                      = true
    skip_blast                        = true

    // BBmap subsampling params
    num_subsamples             = 1000

    // porechop trimming is skipped by default - software is no longer maintained - recommend using adapter trimming function built into dorado

    // set read quality minimum threshold
    chopper_q                  = 15
    chopper_min_len            = 1000
    chopper_max_len            = 2147483647

    // MetaMaps params
    metamaps_db = "/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/metamaps/databases/refseq_complete"
    metamaps_threads = 16
    metamaps_mem = 120

    // Kraken2 params
    kraken_db_main = "/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/kraken-db/bact_arch_vir_fungi_amoeba-DB_41-mer"
    kraken_db_protein = "/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/kraken-db/protein_alanine_tRNA_ligase"
    kraken_custom_params = ""

    // tax-ids that a custom module uses to parse out reads by taxon from kraken classified reads 
    kraken_tax_ids = "5754 5763 1260114"

    // FastqScreen params
    fastq_screen_conf = "${projectDir}/assets/fastq_screen.conf"

    // Specify Assembler here: "flye", "megahit", "spades"
    assembler = 'flye'

    // minimap2 params
    minimap2_meta = 'all-genomes'
    minimap2_index = '/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/minimap2/index/super-genome-refseq.mmi'
    minimap2_mismatch_penalty = 4
    seqid2taxid_map="/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/taxonomy/seqid2taxid_no-strain.map"
    filter_alignment_by_id = false
    my_tax_ids = "${projectDir}/assets/tax_ids_acanth-verm-naegleria.txt"
    include_children = true
    ncbi_taxonomy_nodes = "/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/taxonomy/nodes.dmp"
    ncbi_taxonomy_names = "/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/taxonomy/names.dmp"
    mapping_quality = 20

    // QUAST params
    quast_ref = '/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/reference/bacteria_refseq.fna'

    // BLAST params
    blast_db = "/scicomp/groups-pure/OID/NCEZID/DFWED/WDPB/EMEL/Projects/Long_Read_Analysis_RUSHER/data/blast/arch-bact-fung-hum-amoeba_refseq/arch-bact-fung-hum-amoeba_refseq"

    //BLAST custom params
    blast_evalue = "1e-10"
    blast_perc_identity = "95"
    blast_target_seqs = "5"
    
    // Default nf-core stuff
    igenomes_base              = 's3://ngi-igenomes/igenomes'
    igenomes_ignore            = true

    // MultiQC options
    multiqc_config             = null
    multiqc_title              = null
    multiqc_logo               = null
    max_multiqc_email_size     = '25.MB'
    multiqc_methods_description = null

    // Boilerplate options
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    version                    = false

    // Config options
    config_profile_name        = null
    config_profile_description = null
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_contact     = null
    config_profile_url         = null
    

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '300.GB'
    max_cpus                   = 20
    max_time                   = '300.h'

    // Schema validation default options
    validationFailUnrecognisedParams = false
    validationLenientMode            = false
    validationSchemaIgnoreParams     = 'genomes,igenomes_base'
    validationShowHiddenParams       = false
    validate_params                  = true

}


/////////////////////////////////////////////////////////////
// formats quality score parameter in chopper
params {
    chopper_args = "--quality ${params.chopper_q} --minlength ${params.chopper_min_len} --maxlength ${params.chopper_max_len}"
}

params {
    kraken_args = "${params.kraken_custom_params}"
}


/////////////////////////////////////////////////////////////
// set spades to process metagenomic samples based on params.metagenomic_sample

if (params.metagenomic_sample) {

    params {

        spades_args = '--meta'
        flye_args = '--meta --read-error 0.03'

    }

} else {

    params {

        spades_args = ''
        flye_args = '--read-error 0.03'
    
    }
}

params {

    minimap2_args = "-I30G -B ${params.minimap2_mismatch_penalty} --secondary=no --split-prefix temp -a"

}


// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}


profiles {
    debug {
        dumpHashes             = true
        process.beforeScript   = 'echo $HOSTNAME'
        cleanup                = false
    }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        conda.enabled          = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    podman {
        podman.enabled         = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    shifter {
        shifter.enabled        = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    charliecloud {
        charliecloud.enabled   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        apptainer.enabled      = false
    }
    apptainer {
        apptainer.enabled      = true
        apptainer.autoMounts   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 4
        executor.memory        = 8.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
    local {
        executor {
        name = 'local'
        queueSize = 6
        }
        process {
        executor = 'local'
        memory = '32.GB'
        cpus = 12
        time = '48.h'
        }
    }
    rosalind {
        executor {
        name = 'sge'
        queueSize = 12
        pollInterval = '10sec'
        submitRateLimit = '2sec'
        }
        process {
        // Executor information
        executor = 'sge'
        //jobName = { "$task.name - $task.hash" }
        penv = 'smp'
        queue = { task.time <= 4.h ? 'short.q' : task.time > 7.day ? 'long.q' : 'all.q' }

        // Disable docker by default
        docker.enabled = false

        // Default resources - expected to be overwritten
        memory = '32.GB'
        cpus = 12
        time = '72.h'

        // Set h_vmem option for qsub submissions. +20 memory to h_vmem prevents memory allocation errors.
        clusterOptions = { "-l h_vmem=${(check_max((task.memory.toGiga())+20), 'memory').toString().replaceAll(/[\sB]/,'')}G" }

        // Error handling - increases resources on each retry. Try to ignore errors and continue if not in errors listed.
        errorStrategy = { task.exitStatus in [143,137,104,134,139,140,71,255] ? 'retry' : 'ignore' }
        maxRetries    = 3
        maxErrors     = '-1'
        }
    }
}

// Set default registry for Apptainer, Docker, Podman and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry   = 'quay.io'
docker.registry      = 'quay.io'
podman.registry      = 'quay.io'
singularity.registry = 'quay.io'

// Nextflow plugins
plugins {
    id 'nf-validation' // Validation of pipeline parameters and creation of an input channel from a sample sheet
}

// Load igenomes.config if required
if (!params.igenomes_ignore) {
    includeConfig 'conf/igenomes.config'
} else {
    params.genomes = [:]
}
// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'Meta-ONT'
    author          = """rtq0"""
    homePage        = 'https://git.biotech.cdc.gov/rtq0/long-read-analysis'
    description     = """Analysis workflow for Oxford Nanopore, metagenomic samples"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.04.0'
    version         = '1.0dev'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
